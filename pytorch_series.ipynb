{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1035, 0.6175, 0.2753, 0.4464, 0.5045],\n",
      "        [0.3618, 0.1066, 0.2985, 0.8155, 0.2369]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand([2,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1035, 0.6175, 0.2753, 0.4464, 0.5045, 0.3618, 0.1066, 0.2985, 0.8155,\n",
       "         0.2369]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## .view() is not permanent, use var = var.view() to set it permanently\n",
    "x.view(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = Train, y = Test\n",
    "x = datasets.MNIST(\"\", download = True, train = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "y = datasets.MNIST(\"\", download = True, train = False, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(x, batch_size = 10, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(y, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 2, 3, 1, 6, 6, 0, 8, 1, 2])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0][0], data[1][0] #x is the '255' pixels feature, y = label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()\n",
    "print(data[0][1].shape) # shape 1,28,28 not 28,28, need to be changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "counter_dict = {0:0, 1:0 ,2:0 ,3:0 ,4:0 ,5:0 ,6:0 ,7:0 ,8:0, 9:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "#x = trainset, y = testset\n",
    "for data in trainset:\n",
    "    xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        counter += 1\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 9.871666666666666\n",
      "1 : 11.236666666666666\n",
      "2 : 9.93\n",
      "3 : 10.218333333333334\n",
      "4 : 9.736666666666666\n",
      "5 : 9.035\n",
      "6 : 9.863333333333333\n",
      "7 : 10.441666666666666\n",
      "8 : 9.751666666666667\n",
      "9 : 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "#checking if the data is balanced. Crucial point.\n",
    "for i in counter_dict:\n",
    "    print(f\"{i} : {counter_dict[i]/counter*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) #fc = fully connected layer 'n.1', 28,28 is the rows and columns of the pic in pixels, 64 is         \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64) # 64 is the number passed from the first layer as output, that serves as a input to the next layer\n",
    "        self.fc4 = nn.Linear(64, 10) # 10 classes range(0,10)\n",
    "        \n",
    "    def forward(self, x): # F.relu is the activation function to \"fire\" the neuron if applicable.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim = 1)\n",
    "        \n",
    "    net = Net()\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1,28*28)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4105, -2.3239, -2.3763, -2.3268, -2.2201, -2.2039, -2.4050, -2.3016,\n",
       "         -2.3011, -2.1861]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0099, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        #data i s a batch of featursets and labels\n",
    "        X,y = data\n",
    "        net.zero_grad() #gadiens that hold the loss, that the optimizers will use.\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y) #2 major ways to calcualte loss: 1) hot vector fx.[0,1,0] - meansquared error, in this case nll.loss\n",
    "        loss.backward() # magic, \n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('Accuracy is :',(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
